"""
VOICE CHAT & TTS SERVICE MODULE
-------------------------------
M√¥ t·∫£: File n√†y x·ª≠ l√Ω c√°c ch·ª©c nƒÉng li√™n quan ƒë·∫øn √Çm thanh (Audio).
Ch·ª©c nƒÉng ch√≠nh:
1. K·∫øt n·ªëi v·ªõi Google Gemini Live API qua WebSocket.
2. Text-to-Speech (TTS): Chuy·ªÉn vƒÉn b·∫£n th√†nh gi·ªçng n√≥i.
3. Chat Voice: H·ªôi tho·∫°i 2 chi·ªÅu (User nh·∫Øn text -> AI tr·∫£ l·ªùi b·∫±ng Audio + Text).
4. T√≠ch h·ª£p c∆° ch·∫ø "Jailbreak" cho Voice Chat.
"""

import asyncio
import base64
import json
import websockets
from db_utils import DatabaseManager

class VoiceChatService:
    def __init__(self, api_key: str):
        self.api_key = api_key
        # Model Gemini Flash h·ªó tr·ª£ Audio native
        self.model = "gemini-2.5-flash-native-audio-latest"
        # WebSocket URL
        self.ws_url = f"wss://generativelanguage.googleapis.com/ws/google.ai.generativelanguage.v1beta.GenerativeService.BidiGenerateContent?key={api_key}"
        
        # K·∫øt n·ªëi DB (d·ª± ph√≤ng, hi·ªán t·∫°i Voice ch∆∞a l∆∞u history nh∆∞ng c√≥ s·∫µn ƒë·ªÉ d√πng)
        self.db_manager = DatabaseManager()

    async def text_to_speech(self, text: str, voice: str = "Puck") -> bytes:
        """
        Chuy·ªÉn ƒë·ªïi Text th√†nh Audio (TTS).
        S·ª≠ d·ª•ng WebSocket ƒë·ªÉ g·ª≠i text v√† nh·∫≠n v·ªÅ c√°c chunk audio PCM.
        """
        audio_chunks = []
        try:
            async with websockets.connect(self.ws_url) as ws:
                # 1. G·ª≠i tin nh·∫Øn Setup (c·∫•u h√¨nh voice)
                setup_message = {
                    "setup": {
                        "model": f"models/{self.model}",
                        "systemInstruction": {
                            "parts": [{"text": "You are a helpful reading assistant. Read the provided text clearly and naturally."}]
                        },
                        "generationConfig": {
                            "responseModalities": ["AUDIO"],
                            "speechConfig": {
                                "voiceConfig": {
                                    "prebuiltVoiceConfig": {
                                        "voiceName": voice
                                    }
                                }
                            }
                        }
                    }
                }
                
                await ws.send(json.dumps(setup_message))
                setup_resp = await ws.recv() # ƒê·ª£i x√°c nh·∫≠n setup
                print(f"‚úÖ TTS Setup Response: {setup_resp}")
                
                # 2. G·ª≠i y√™u c·∫ßu ƒë·ªçc vƒÉn b·∫£n
                prompt_message = {
                    "clientContent": {
                        "turns": [{
                            "role": "user",
                            "parts": [{"text": f"Please read this text aloud: {text}"}]
                        }],
                        "turnComplete": True
                    }
                }
                
                await ws.send(json.dumps(prompt_message))
                
                # 3. Nh·∫≠n ph·∫£n h·ªìi
                while True:
                    try:
                        response = await asyncio.wait_for(ws.recv(), timeout=10.0)
                        data = json.loads(response)
                        
                        if "serverContent" in data:
                            server_content = data["serverContent"]
                            if "modelTurn" in server_content:
                                parts = server_content["modelTurn"].get("parts", [])
                                for part in parts:
                                    if "inlineData" in part: # Audio data
                                        audio_b64 = part["inlineData"]["data"]
                                        audio_chunks.append(base64.b64decode(audio_b64))
                            if server_content.get("turnComplete", False):
                                break
                    except asyncio.TimeoutError:
                        break
                    except Exception:
                        break
        except Exception as e:
            print(f"TTS WebSocket error: {e}")
            raise
        
        return b''.join(audio_chunks)
    async def chat_with_voice(self, message: str, voice: str = "Puck", conversation_history: list = None, language: str = "vi", audio_input: str = None, mime_type: str = "audio/wav") -> dict:
        """
        Chat Voice 2 chi·ªÅu.
        Input: Tin nh·∫Øn text c·ªßa User.
        Output: Audio gi·ªçng n√≥i c·ªßa AI + Text ph·∫£n h·ªìi.
        """
        audio_chunks = []
        response_text = ""
        
        try:
            async with websockets.connect(self.ws_url) as ws:
                # 1. Setup session
                # Gemini Multimodal Live API (WebSocket) 
                # D√πng camelCase cho protocol WebSocket v1beta
                setup_message = {
                    "setup": {
                        "model": f"models/{self.model}",
                        "systemInstruction": { 
                            "parts": [{"text": f"You are a helpful voice assistant. Listen to the user's audio or read their text, transcribe/process it, and respond naturally in {language}. DO NOT output your internal thoughts, reasoning, or headers. ONLY output the final spoken response."}]
                        },
                        "generationConfig": { 
                            "responseModalities": ["AUDIO"], 
                            "speechConfig": {
                                "voiceConfig": {
                                    "prebuiltVoiceConfig": {"voiceName": voice}
                                }
                            }
                        }
                    }
                }
                
                await ws.send(json.dumps(setup_message))
                try:
                    setup_confirm_raw = await asyncio.wait_for(ws.recv(), timeout=10.0)
                    setup_confirm = json.loads(setup_confirm_raw)
                    print(f"‚úÖ Voice Chat Setup Response: {setup_confirm_raw}", flush=True)
                    
                    if "setupComplete" not in setup_confirm:
                        print(f"üõë Gemini Setup Failed! Response: {setup_confirm_raw}", flush=True)
                except asyncio.TimeoutError:
                    print("üõë Setup Timeout: Gemini did not respond to setup message.", flush=True)
                    raise Exception("Gemini Setup Timeout")
                
                # 2. Tin nh·∫Øn h·ªôi tho·∫°i
                turns = []
                
                # 3. Th√™m tin nh·∫Øn hi·ªán t·∫°i (H·ªó tr·ª£ c·∫£ MESSAGE TEXT v√† AUDIO)
                current_parts = []
                
                if message:
                    print(f"üí¨ Text input detected: {message}", flush=True)
                    current_parts.append({"text": message})
                
                if audio_input:
                    # Log ƒë·ªãnh d·∫°ng g·ªëc ƒë·ªÉ debug
                    print(f"DEBUG: Original Mime: {mime_type}", flush=True)
                    audio_bytes_raw = base64.b64decode(audio_input)
                    audio_bytes_len = len(audio_bytes_raw)
                    print(f"üì• Input Audio Size: {audio_bytes_len} bytes", flush=True)
                    
                    final_mime = "audio/webm;codecs=opus" if "webm" in mime_type.lower() else "audio/l16;rate=24000"
                    processed_audio = audio_input
                    
                    if "wav" in final_mime.lower() or "l16" in final_mime.lower():
                        if audio_bytes_raw.startswith(b'RIFF'):
                            print("‚úÇÔ∏è [WAV] Detected RIFF header. Stripping 44 bytes...", flush=True)
                            audio_bytes_stripped = audio_bytes_raw[44:]
                            processed_audio = base64.b64encode(audio_bytes_stripped).decode('utf-8')

                    print(f"üé§ Sending Audio to Gemini with MIME: {final_mime}", flush=True)
                    current_parts.append({
                        "inlineData": { 
                            "mimeType": final_mime,
                            "data": processed_audio
                        }
                    })
                
                if not current_parts:
                    raise Exception("No input provided (neither text nor audio)")

                turns.append({
                    "role": "user",
                    "parts": current_parts
                })

                # --- FINAL TURNS ---
                final_turns = turns
                
                # 4. G·ª≠i to√†n b·ªô n·ªôi dung
                prompt_input = {
                    "clientContent": {
                        "turns": final_turns,
                        "turnComplete": True
                    }
                }
                
                print(f"DEBUG: Prompt Request: {json.dumps(prompt_input)[:200]}...")
                await ws.send(json.dumps(prompt_input))
                
                # 5. Nh·∫≠n ph·∫£n h·ªìi (Audio + Text)
                print("‚è≥ Waiting for Gemini response...")
                while True:
                    try:
                        response = await asyncio.wait_for(ws.recv(), timeout=15.0)
                        data = json.loads(response)
                        
                        # Debug: Log response structure
                        # print(f"üì° WebSocket Response: {data}") # TOO NOISY
                        
                        if "serverContent" in data:
                            server_content = data["serverContent"]
                            if "modelTurn" in server_content:
                                parts = server_content["modelTurn"].get("parts", [])
                                print(f"üì¶ Received {len(parts)} parts from Gemini")
                                for part in parts:
                                    if "text" in part: # Nh·∫≠n Text
                                        response_text += part["text"]
                                        print(f"üìù Text part: {part['text'][:100]}...")
                                    if "inlineData" in part: # Nh·∫≠n Audio chunks
                                        audio_b64 = part["inlineData"]["data"]
                                        audio_chunks.append(base64.b64decode(audio_b64))
                                        print(f"üîä Audio chunk: {len(audio_b64)} bytes (base64)")
                        if server_content.get("turnComplete", False):
                                print("DEBUG: Turn Complete received")
                                break
                        else:
                            print(f"‚ö†Ô∏è Unexpected response keys: {data.keys()}")
                            if "error" in data:
                                print(f"üõë Gemini Error Data: {json.dumps(data['error'])}")
                    except asyncio.TimeoutError:
                        print("‚è±Ô∏è WebSocket timeout")
                        break
                    except Exception as e:
                        print(f"‚ùå WebSocket receive error: {e}")
                        break
                        
        except Exception as e:
            import traceback
            print(f"Voice Chat WebSocket error: {e}")
            print(traceback.format_exc())
            raise
            
        # 6. Chu·∫©n b·ªã k·∫øt qu·∫£
        # Th√™m 0.3s im l·∫∑ng (\x00) v√†o ƒë·∫ßu ƒë·ªÉ tr√°nh Chrome b·ªã m·∫•t ti·∫øng l√∫c b·∫Øt ƒë·∫ßu (Hardware lag)
        # 24000 samples/s * 0.3s * 2 bytes = 14400 bytes
        silence_padding = b'\x00' * int(24000 * 0.3 * 2)
        raw_audio = silence_padding + b''.join(audio_chunks)
        total_audio_len = len(raw_audio)
        
        # Estimate duration: Gemini output is usually 24kHz, 16-bit PCM mono
        duration_sec = total_audio_len / (24000 * 2) 
        print(f"üé§ AI Response: {len(response_text)} chars, {total_audio_len} bytes (~{duration_sec:.2f}s, included 0.3s padding)")
        
        # Filter out thoughts/headers (lines starting with ** or similar)
        import re
        clean_text = re.sub(r'\*\*.*?\*\*', '', response_text).strip() # Remove **Header**
        # Remove lines that look like reasoning if mixed (simple heuristic)
        
        return {
            "text": clean_text if clean_text else response_text.strip(),
            "audio": raw_audio
        }
